<!doctype html><!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: July 9, 2023 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.397f28e4130d019041421443f6e6c219.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=description content="A highly-customizable Hugo academic resume theme powered by Wowchemy website builder."><link rel=alternate hreflang=en-us href=https://westlake-nlp.github.io/publication-type/1/><link rel=canonical href=https://westlake-nlp.github.io/publication-type/1/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hua5de30d51c364d4bdd140e3e0b499a9a_251609_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hua5de30d51c364d4bdd140e3e0b499a9a_251609_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#ff7b00"><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@wowchemy"><meta property="twitter:creator" content="@wowchemy"><meta property="twitter:image" content="https://westlake-nlp.github.io/media/icon_hua5de30d51c364d4bdd140e3e0b499a9a_251609_512x512_fill_lanczos_center_3.png"><meta property="og:site_name" content="WestlakeNLP"><meta property="og:url" content="https://westlake-nlp.github.io/publication-type/1/"><meta property="og:title" content="1 | WestlakeNLP"><meta property="og:description" content="A highly-customizable Hugo academic resume theme powered by Wowchemy website builder."><meta property="og:image" content="https://westlake-nlp.github.io/media/icon_hua5de30d51c364d4bdd140e3e0b499a9a_251609_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2022-12-01T00:00:00+00:00"><link rel=alternate href=/publication-type/1/index.xml type=application/rss+xml title=WestlakeNLP><title>1 | WestlakeNLP</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper><script src=/js/wowchemy-init.min.90c664d12df6e4e8e3cfc88247da8a81.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>WestlakeNLP</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>WestlakeNLP</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#introduction><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#posts><span>News</span></a></li><li class=nav-item><a class=nav-link href=/#people><span>People</span></a></li><li class=nav-item><a class=nav-link href=/#publication><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#teaching><span>Teaching</span></a></li><li class=nav-item><a class=nav-link href=/projects/><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/reading/><span>Reading Group</span></a></li><li class=nav-item><a class=nav-link href=/talks/><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Joining</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class="universal-wrapper pt-3"><h1>1</h1></div><div class=universal-wrapper><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2022.-on-the-role-of-pre-trained-language-models-in-word-ordering-a-case-study-with-bart/>On the Role of Pre-trained Language Models in Word Ordering: A Case Study with BART</a></div><a href=/publication/2022.-on-the-role-of-pre-trained-language-models-in-word-ordering-a-case-study-with-bart/ class=summary-link><div class=article-style>Word ordering is a constrained language generation task taking unordered words as input. Existing work uses linear models and neural …</div></a><div class="stream-meta article-metadata"><div><span>Zebin Ou</span>, <span>Meishan Zhang</span>, <span>Yue Zhang</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://aclanthology.org/2022.coling-1.567.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2022.-on-the-role-of-pre-trained-language-models-in-word-ordering-a-case-study-with-bart/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/2022.-on-the-role-of-pre-trained-language-models-in-word-ordering-a-case-study-with-bart/><img src=/publication/2022.-on-the-role-of-pre-trained-language-models-in-word-ordering-a-case-study-with-bart/featured_hu0701af9fc8b489be653eb581d1071eaf_214168_150x0_resize_q75_h2_lanczos.webp height=37 width=150 alt="On the Role of Pre-trained Language Models in Word Ordering: A Case Study with BART" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2022.-recent-advances-in-text-to-sql-a-survey-of-what-we-have-and-what-we-expect/>Recent Advances in Text-to-SQL: A Survey of What We Have and What We Expect</a></div><a href=/publication/2022.-recent-advances-in-text-to-sql-a-survey-of-what-we-have-and-what-we-expect/ class=summary-link><div class=article-style>Text-to-SQL has attracted attention from both the natural language processing and database communities because of its ability to …</div></a><div class="stream-meta article-metadata"><div><span>Naihao Deng</span>, <span>Yulong Chen</span>, <span>Yue Zhang</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://aclanthology.org/2022.coling-1.190.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2022.-recent-advances-in-text-to-sql-a-survey-of-what-we-have-and-what-we-expect/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/2022.-recent-advances-in-text-to-sql-a-survey-of-what-we-have-and-what-we-expect/><img src=/publication/2022.-recent-advances-in-text-to-sql-a-survey-of-what-we-have-and-what-we-expect/featured_hufd3ba1a4c021625fa987b8b74d058b5e_214168_150x0_resize_q75_h2_lanczos.webp height=67 width=150 alt="Recent Advances in Text-to-SQL: A Survey of What We Have and What We Expect" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2022.-semantic-based-pre-training-for-dialogue-understanding/>Semantic-based Pre-training for Dialogue Understanding</a></div><a href=/publication/2022.-semantic-based-pre-training-for-dialogue-understanding/ class=summary-link><div class=article-style>Pre-trained language models have made great progress on dialogue tasks. However, these models are typically trained on surface dialogue …</div></a><div class="stream-meta article-metadata"><div><span>Xuefeng Bai</span>, <span>Linfeng Song</span>, <span>Yue Zhang</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://aclanthology.org/2022.coling-1.49.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2022.-semantic-based-pre-training-for-dialogue-understanding/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/2022.-semantic-based-pre-training-for-dialogue-understanding/><img src=/publication/2022.-semantic-based-pre-training-for-dialogue-understanding/featured_hu157d914dd6b6f4b6622d22c967eb2035_214168_150x0_resize_q75_h2_lanczos.webp height=40 width=150 alt="Semantic-based Pre-training for Dialogue Understanding" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2022.-speeding-up-transformer-decoding-via-an-attention-refinement-network/>Speeding up Transformer Decoding via an Attention Refinement Network</a></div><a href=/publication/2022.-speeding-up-transformer-decoding-via-an-attention-refinement-network/ class=summary-link><div class=article-style>Despite the revolutionary advances made by Transformer in Neural Machine Translation (NMT), inference efficiency remains an obstacle …</div></a><div class="stream-meta article-metadata"><div><span>Kaixin Wu</span>, <span>Yue Zhang</span>, <span>Bojie Hu</span>, <span>Tong Zhang</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://aclanthology.org/2022.coling-1.453.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2022.-speeding-up-transformer-decoding-via-an-attention-refinement-network/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/2022.-speeding-up-transformer-decoding-via-an-attention-refinement-network/><img src=/publication/2022.-speeding-up-transformer-decoding-via-an-attention-refinement-network/featured_hud0cddbe56a49a841984605a18d964e60_214168_150x0_resize_q75_h2_lanczos.webp height=85 width=150 alt="Speeding up Transformer Decoding via an Attention Refinement Network" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2022.-usb-a-unified-semi-supervised-learning-benchmark-for-classification/>USB: A Unified Semi-supervised Learning Benchmark for Classification</a></div><a href=/publication/2022.-usb-a-unified-semi-supervised-learning-benchmark-for-classification/ class=summary-link><div class=article-style>Semi-supervised learning (SSL) improves model generalization by leveraging massive unlabeled data to augment limited labeled samples. …</div></a><div class="stream-meta article-metadata"><div><span>Yidong Wang</span>, <span>Hao Chen</span>, <span>Yue Fan</span>, <span>Wang Sun</span>, <span>Ran Tao</span>, <span>Wenxin Hou</span>, <span>Renjie Wang</span>, <span>Linyi Yang</span>, <span>Zhi Zhou</span>, <span>Lan-Zhe Guo</span>, <span>Heli Qi</span>, <span>Zhen Wu</span>, <span>Yu-Feng Li</span>, <span>Satoshi Nakamura</span>, <span>Wei Ye</span>, <span>Marios Savvides</span>, <span>Bhiksha Raj</span>, <span>Takahiro Shinozaki</span>, <span>Bernt Schiele</span>, <span>Jindong Wang</span>, <span>Xing Xie</span>, <span>Yue Zhang</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/pdf/2208.07204.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2022.-usb-a-unified-semi-supervised-learning-benchmark-for-classification/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/2022.-usb-a-unified-semi-supervised-learning-benchmark-for-classification/><img src=/publication/2022.-usb-a-unified-semi-supervised-learning-benchmark-for-classification/featured_hu2578967f1a843e21550380387360d5fd_214168_150x0_resize_q75_h2_lanczos.webp height=89 width=150 alt="USB: A Unified Semi-supervised Learning Benchmark for Classification" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2022.-contrastive-latent-variable-models-for-neural-text-generation/>Contrastive Latent Variable Models for Neural Text Generation</a></div><a href=/publication/2022.-contrastive-latent-variable-models-for-neural-text-generation/ class=summary-link><div class=article-style>Deep latent variable models such as variational autoencoders and energy-based models are widely used for neural text generation. Most …</div></a><div class="stream-meta article-metadata"><div><span>Zhiyang Teng</span>, <span>Chenhua Chen</span>, <span>Yan Zhang</span>, <span>Yue Zhang</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/pdf?id=HMMlduUicg9" target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2022.-contrastive-latent-variable-models-for-neural-text-generation/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/2022.-contrastive-latent-variable-models-for-neural-text-generation/><img src=/publication/2022.-contrastive-latent-variable-models-for-neural-text-generation/featured_hubdcc8b98c3088648f06e316b105b8622_214168_150x0_resize_q75_h2_lanczos.webp height=95 width=150 alt="Contrastive Latent Variable Models for Neural Text Generation" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2022.-towards-event-level-causal-relation-identification/>Towards Event-Level Causal Relation Identification</a></div><a href=/publication/2022.-towards-event-level-causal-relation-identification/ class=summary-link><div class=article-style>Existing methods usually identify causal relations between events at the mention-level, which takes each event mention pair as a …</div></a><div class="stream-meta article-metadata"><div><span>Chuang Fan</span>, <span>Daoxing Liu</span>, <span>Libo Qin</span>, <span>Yue Zhang</span>, <span>Ruifeng Xu</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href="https://dl.acm.org/doi/pdf/10.1145/3477495.3531758?casa_token=_fyqeDP_TCEAAAAA:nX-R6gdMwBbvS6T93wMMALtF--0B5oDmGH00BMuo31fNJjpf0nJ3vH2vPovlg1G-BwCW8yboXpo3rLQ" target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2022.-towards-event-level-causal-relation-identification/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/2022.-towards-event-level-causal-relation-identification/><img src=/publication/2022.-towards-event-level-causal-relation-identification/featured_hu80f8eb752cc09f893a2012c638cbd321_214168_150x0_resize_q75_h2_lanczos.webp height=93 width=150 alt="Towards Event-Level Causal Relation Identification" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2022.-numhtml-numeric-oriented-hierarchical-transformer-model-for-multi-task-financial-forecasting/>NumHTML: Numeric-Oriented Hierarchical Transformer Model for Multi-Task Financial Forecasting</a></div><a href=/publication/2022.-numhtml-numeric-oriented-hierarchical-transformer-model-for-multi-task-financial-forecasting/ class=summary-link><div class=article-style>Financial forecasting has been an important and active area of machine learning research because of the challenges it presents and the …</div></a><div class="stream-meta article-metadata"><div><span>Linyi Yang</span>, <span>Jiazheng Li</span>, <span>Ruihai Dong</span>, <span>Yue Zhang</span>, <span>Barry Smyth</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://ojs.aaai.org/index.php/AAAI/article/view/21414/21163 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2022.-numhtml-numeric-oriented-hierarchical-transformer-model-for-multi-task-financial-forecasting/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/2022.-numhtml-numeric-oriented-hierarchical-transformer-model-for-multi-task-financial-forecasting/><img src=/publication/2022.-numhtml-numeric-oriented-hierarchical-transformer-model-for-multi-task-financial-forecasting/featured_hu31e479104493e49623daea333880d122_214168_150x0_resize_q75_h2_lanczos.webp height=75 width=150 alt="NumHTML: Numeric-Oriented Hierarchical Transformer Model for Multi-Task Financial Forecasting" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2022.-a-graph-enhanced-bert-model-for-event-prediction/>A Graph Enhanced BERT Model for Event Prediction</a></div><a href=/publication/2022.-a-graph-enhanced-bert-model-for-event-prediction/ class=summary-link><div class=article-style>Predicting the subsequent event for an existing event context is an important but challenging task, as it requires understanding the …</div></a><div class="stream-meta article-metadata"><div><span>Li Du</span>, <span>Xiao Ding</span>, <span>Yue Zhang</span>, <span>Ting Liu</span>, <span>Bing Qin</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://frcchang.github.io/pub/2022.findings-acl.206.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2022.-a-graph-enhanced-bert-model-for-event-prediction/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/2022.-a-graph-enhanced-bert-model-for-event-prediction/><img src=/publication/2022.-a-graph-enhanced-bert-model-for-event-prediction/featured_hub0bb96b59953c668c5a1e3d0bd4980e3_214168_150x0_resize_q75_h2_lanczos.webp height=46 width=150 alt="A Graph Enhanced BERT Model for Event Prediction" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2022.-a-rationale-centric-framework-for-human-in-the-loop-machine-learning/>A Rationale-Centric Framework for Human-in-the-loop Machine Learning</a></div><a href=/publication/2022.-a-rationale-centric-framework-for-human-in-the-loop-machine-learning/ class=summary-link><div class=article-style>We present a novel rational-centric framework with human-in-the-loop Rationales-centric Double-robustness Learning (RDL) to boost model …</div></a><div class="stream-meta article-metadata"><div><span>Jinghui Lu</span>, <span>Linyi Yang</span>, <span>Brian Mac Namee</span>, <span>Yue Zhang</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://aclanthology.org/2022.acl-long.481.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2022.-a-rationale-centric-framework-for-human-in-the-loop-machine-learning/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/2022.-a-rationale-centric-framework-for-human-in-the-loop-machine-learning/><img src=/publication/2022.-a-rationale-centric-framework-for-human-in-the-loop-machine-learning/featured_hu8d51b2c8e3ab07c1f85d0294b7b6e28e_214168_150x0_resize_q75_h2_lanczos.webp height=83 width=150 alt="A Rationale-Centric Framework for Human-in-the-loop Machine Learning" loading=lazy></a></div></div><nav class=mt-1><ul class="pagination justify-content-center"><li class=page-item><a class=page-link href=/publication-type/1/>&#171;</a></li><li class=page-item><a class=page-link href=/publication-type/1/page/3/>&#187;</a></li></ul></nav></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.32ee83730ed883becad04bc5170512cc.js></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script>
<script src=/en/js/wowchemy.min.91534f6cb18c3621254d412c69186d7c.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>